# Cellophane

A library for creating modular wrappers.

# â—ï¸ HERE BE DRAGONS ðŸ‰ â—ï¸

Cellophane is currently very unstable and may break, blow up, and/or eat your pet(s), etc.

## Usage

Add cellophane as a subtree (or a submodule) at the base of your project. A generic project structure can be generated with `cellophane init`.

```shell
# Initialize an empty git repo
git init my_awesome_wrapper
cd my_awesome_wrapper

# Add the cellophane repo as a remote and install cellophane as a subtree in the project root
git remote add -f cellophane https://github.com/dodslaser/cellophane
git subtree add --prefix cellophane cellophane main --squash

# Initialize an empty cellophane project
python -m cellophane init --path .

# To upgrade to the latest commit on main
git fetch cellophane
git subtree pull --prefix cellophane cellophane main --squash -m "Upgrade cellophane"
```

A wrapper directory structure should look something like this:

```
./my_awesome_wrapper/
â”‚   # Cellophane module subtree
â”œâ”€â”€ cellophane
â”‚   â””â”€â”€ ...
â”‚
â”‚   # Directory containing cellophane modules
â”œâ”€â”€ modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ my_module.py
â”‚   â””â”€â”€ another_module
â”‚       |   # Modules can contain module specific schemas that will be merged with the wrapper schema
â”‚       â”œâ”€â”€ schema.yaml
â”‚       â”œâ”€â”€ scripts
â”‚       â”‚   â”‚   # Modules may contain module specific scripts/data
â”‚       â”‚   â””â”€â”€ module_script.sh
â”‚       â”œâ”€â”€ data
â”‚       â”‚   â””â”€â”€ some_data.txt
â”‚       â””â”€â”€ __init__.py
â”‚
â”‚   # Directory containing scripts to be submitted by Popen, SGE, etc.
â”œâ”€â”€ scripts
â”‚   â””â”€â”€ my_script.sh
â”‚
â”‚   # Directory containing misc. files used by the wrapper.
â”œâ”€â”€ scripts
â”‚   â””â”€â”€ some_more_data.txt
â”‚
â”‚   # JSON Schema defining configuration options
â”œâ”€â”€ schema.yaml
â”‚
â”‚   # Main entrypoint for the wrapper
â””â”€â”€ __main__.py
â”‚
â”‚   # Alternative entrypoint for the wrapper
â””â”€â”€ my_awesome_wrapper.py
```

If for some reason you need to change this structure you can change `__main__.py` as such:

```python
from cellophane import cellophane

if __name__ == "__main__":
    main = cellphane(
        "My Awesome Wrapper" # Will be used for logging
        modules_path=Path(__file__) / "my_modules"
        schema_path=Path(__file__) / "schema.yaml"
    )

    main(prog_name="my_awesome_wrapper")
```

Pre-made modules can also be added from git

```shell
# Add the module repo as a remote and install a module as a subtree
git remote add -f modules https://github.com/dodslaser/cellophane_modules
git subtree add --prefix modules/slims modules slims --squash -m "Add SLIMS module"

# Upgrading is done the same way as cellophane
git fetch modules
git subtree pull --prefix modules/slims modules slims --squash -m "Upgrade SLIMS module"
```

A cellophane wrapper can be run as a script or as a module

```shell
# As a module
python -m my_awesome_wrapper [...]

# As a script
python ./my_awesome_wrapper.py [...]
```

## Configuration

Configuration options must be defined as a JSON Schema in a YAML file. By default, cellophane will use `schema.yaml` located in your project root. To oveerride use `cellophane.cellophane(schema_path=Path(...))`. The schema will be merged with base schema (`schema.yaml` in this repo) which contains configuration options required by all cellophane wrappers (eg. SLIMS API user/key). **NOTE:** *More complex JSON schemas may work, but are also more likely break the parsing.*

CLI flags for all configuration options specified in the schema are generated automagically. A YAML config file can be passed with the `--config_file` / `-c` flag.

Here's the bease `schema.yaml` as an example:

```yaml
type: object
required:
  - foo
  - bar
  - nextflow

properties:
  foo:
    # Nested parameters (type: object) are allowed.
    properties:
      baz:
        # Description will be used to generate help messages
        description: Some other parameter
        # Enum is used to limit choices for a parameter 
        enum:
          - HELLO
          - WORLD
        type: string
      # Flags are joined by underscores. (eg. foo.skip will become --foo_skip).
      skip:
        default: false
        description: Skip foo
        # Bools will result in on/off style flags
        type: boolean
    # required needs to be defined on the correct nesting level
    required:
      - baz
    type: object

  nextflow:
    properties:
      cluster_options:
        description: Nextflow cluster options
        type: string
      config:
        description: Nextflow config file
        # The path type can be used to desingate strings that should be treated as paths 
        type: path
      profile:
        description: Nextflow profile
        type: string
      resume:
        default: false
        description: Resume previous nextflow run
        type: boolean
      sge_pe:
        description: SGE parallel environment for nextflow manager
        type: string
      sge_queue:
        description: SGE queue for nextflow manager
        type: string
      sge_slots:
        description: SGE slots (threads) for nextflow manager
        type: integer
      workdir:
        description: Nextflow work directory
        type: path
    required:
      - sge_queue
      - sge_pe
      - sge_slots
      - profile
      - workdir
    type: object
```

This is the resulting auto-generated CLI:

```shell
$ python -m my_awesome_wrapperrunpy


 Usage: my_awesome_wrapper [OPTIONS]

â•­â”€ Options â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ --outdir                                PATH                                 Output directory                                                                        â”‚
â”‚ --logdir                                PATH                                 Log directory                                                                           â”‚
â”‚ --log_level                             [DEBUG|INFO|WARNING|ERROR|CRITICAL]  Log level [default: INFO]                                                               â”‚
â”‚ --samples_file                          PATH                                 Path YAML file with sample names and paths to fastq files (eg. sample: [fastq1, fastq2] â”‚
â”‚ --foo_skip                                                                   Skip foo                                                                                â”‚
â”‚ --foo_baz                               [HELLO|WORLD]                        Some other parameter                                                                    â”‚
â”‚ --nextflow_cluster_options              TEXT                                 Nextflow cluster options                                                                â”‚
â”‚ --nextflow_workdir                      PATH                                 Nextflow work directory                                                                 â”‚
â”‚ --nextflow_resume                                                            Resume previous nextflow run                                                            â”‚
â”‚ --nextflow_profile                      TEXT                                 Nextflow profile                                                                        â”‚
â”‚ --nextflow_config                       PATH                                 Nextflow config file                                                                    â”‚
â”‚ --nextflow_sge_slots                    INTEGER                              SGE slots (threads) for nextflow manager                                                â”‚
â”‚ --nextflow_sge_pe                       TEXT                                 SGE parallel environment for nextflow manager                                           â”‚
â”‚ --nextflow_sge_queue                    TEXT                                 SGE queue for nextflow manager                                                          â”‚
â”‚ --config                                PATH                                 Path to config file                                                                     â”‚
â”‚ --help                                                                       Show this message and exit.                                                             â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

![Magic](https://i.imgur.com/6KBoYgJ.gif)

## Defining pipeline modules

At least one module must contain at least one `runner` decorated function. Runners are responsible for launching the pipeline with the provided samples. They are executed as separate processes in parallel. Optinally, if `individual_samples=True` is specified in the `runner` decorator cellophane will spawn one runner process per sample. A `runner` function must accept `samples`, `config`, `timestamp`, `label`, `logger`, and `root` as arguments.

A module may also define pre/post-hooks. These are functions that will be executed before or after the whle pipeline completes. A hook function must take `config`, `samples`, amd `logger` as arguments. Hooks are executed sequentially and can be given a numeric priority to ensure correct execution order. By default the priority will be `inf`. Setting a lower `priority` means the hook will be executed earlier.

The main use-case for pre-hooks is to modify `samples` before it is passed to the runners. This can be used to eg. download `.fastq.gz` files from a backup location, decompress `.fasterq` files, add related samples, remove samples with missing files, and so on. If a pre-hook returns a `cellophane.data.Samples` (or a subclass) object it will replace the current `samples`.

The use-case for post-hooks is mayble less obvious, ut they can be used to eg. clean up temporary files, or send an email when a pipeline completes/fails. If your runner returns a `cellophane.data.Samples` (or a subclass) object this will be used by post-hooks, otherwise the original samples will be used. The samples supplied to a post-hook differs from pre-hooks/runners:

1. Samples are combined from all runners. If yout workflow has multiple runners you will get multiple instances of the same sample.
3. Samples will contain `complete` (bool) and `runner` (str) attributes to designate what runner produced them and if it completed

Note that hooks are not module specific, but rather ALL pre-hooks will be executed before ALL runners and ALL post-hooks will be executed afterwards. Module specific functionality should be handeled inside the runner function.

```python
# modules/my_module.py

from pathlib import Path

from cellophane import sge, modules

@modules.pre_hook(priority=10)
def filter_missing(samples, config, timestamp, logger, root):
    _samples = [s for s in samples if all(Path(p).exists() for p in s.fastq_paths)]
    return Samples(_samples)


@modules.runner()
def foo(samples, config, timestamp, label, logger, root):

    # config is a UserDict that allows attrubute access
    if not config.foo.skip:
        # Logging is preconfigured
        logger.info("Important information about foo")
        logger.debug(f"Some less important debug information about {config.foo.baz}")

        # Note that in reality outdir must be accessible on all SGE nodes
        outdir = Path("/tmp/foo")

        # Sample sheets for nf-core can be generated automatically
        sample_sheet = samples.nfcore_samplesheet(
            location=outdir,
            # kwargs will be added as a column to the samplesheet
            # kwargs can also be a sample_id -> value mapping (i.e. a dict)
            strandedness=config.rnafusion.strandedness,
        )


        # sge.submit submits scripts jobs to an SGE cluster (via DRMAA)
        sge.submit(
            str(scripts_path / "nextflow.sh"),
            # *args will be passed as arguments to the script
            *(
                f"-log {outdir / 'logs' / 'foo.log'}",
                (
                    # Note that config still behaves as a dict
                    f"-config {config.nextflow.config}"
                    if "config" in config.nextflow
                    else ""
                ),
                f"run {config.nextflow.main}",
                "-ansi-log false",
            ),
            # Environment variables can be passed to the worker node
            env={"MY_VAR": "foo"},
            queue=config.nextflow.sge_queue,
            pe=config.nextflow.sge_pe,
            slots=config.nextflow.sge_slots,
            # Setting check True blocks until the job is done or fails
            check=True,
            name="foo",
            stderr=config.logdir / f"foo.err",
            stdout=config.logdir / f"foo.out",
            cwd=outdir,
        )

# individual_samples=True will spawn one process for each sample
# label="My Fancy Label" lets you use a label other than the function name (primarily for logging)
@modules.runner(
    individual_samples=True,
    label="My Fancy Label"
)
def bar(samples, config, timestamp, logger, root):

    # samples is still a sequence but length is 1
    sample = samples[0]
    logger.debug(f"Processing {sample.id}")

```

## To-do:

- Improve logging to file
- Handle of complex JSON schemas
- Add functionality for generating `hydra-genetics` units.tsv/samples.tsv
- Make hook priority overridable
